{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 128, 128)\n",
      "X_train size : 100000\n",
      "X_test size : 18149\n"
     ]
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Let's read the data\n",
    "import numpy as np\n",
    "sample = np.load('../data/x_train/0.npz')\n",
    "data = sample['data']\n",
    "print(data.shape)\n",
    "\n",
    "# Let's see how many samples we have\n",
    "print(f\"X_train size : {len(os.listdir('../data/x_train'))}\")\n",
    "print(f\"X_test size : {len(os.listdir('../data/x_test'))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the first benchmark\n",
    "def benchmark(x_test_dir):\n",
    "    n_t_out, out_size = 8, 2\n",
    "    in_size = 128\n",
    "    crop = (in_size - out_size) // 2\n",
    "    benchmark_prediction = []\n",
    "    benchmark_ids = []\n",
    "    for file in os.listdir(x_test_dir):\n",
    "        x_test = np.load(f'{x_test_dir}/{file}')\n",
    "        y_bench = np.concatenate([\n",
    "            x_test['data'][-1:, crop:-crop, crop:-crop] \n",
    "            for _ in range(n_t_out)\n",
    "        ])\n",
    "        benchmark_prediction.append(y_bench.mean(axis=(1, 2)))\n",
    "        benchmark_ids.append(x_test['target_ids'])\n",
    "    return pd.DataFrame({\n",
    "        'ID': np.concatenate(benchmark_ids), \n",
    "        'TARGET': np.concatenate(benchmark_prediction)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the second benchmark\n",
    "get_method = None\n",
    "extrapolation = None\n",
    "\n",
    "def benchmark_pysteps(x_test_dir):\n",
    "    n_t_out, out_size = 8, 2\n",
    "    in_size = 128\n",
    "    crop = (in_size - out_size) // 2\n",
    "    benchmark_prediction = []\n",
    "    benchmark_ids = []\n",
    "    pysteps_flow_method = get_method('LK')\n",
    "    for file in os.listdir(x_test_dir):\n",
    "\n",
    "        x_test = np.load(f'{x_test_dir}/{file}')\n",
    "        motion_field = pysteps_flow_method(x_test['data'])\n",
    "\n",
    "        predictions = extrapolation.forecast(\n",
    "            x_test['data'][-1, ...], \n",
    "            motion_field, \n",
    "            n_t_out\n",
    "        )\n",
    "\n",
    "        predictions[np.isnan(predictions)] = 0.\n",
    "\n",
    "        benchmark_prediction.append(\n",
    "            predictions[:, crop:-crop, crop:-crop].mean(axis=(1, 2))\n",
    "        )\n",
    "\n",
    "        benchmark_ids.append(x_test['target_ids'])\n",
    "        \n",
    "    return pd.DataFrame({\n",
    "        'ID': np.concatenate(benchmark_ids), \n",
    "        'TARGET': np.concatenate(benchmark_prediction)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's seem we have a have enough data to train a neural network. There is spatial and space dependancies. We can try a convolutionnal model to extract features and then a recurrent model to predict the next frame. Or we could directly use a 3D convolutionnal layer to extract spatio-temporal features. I will try both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first define commun class/function needed\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# First i need a custom dataset\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x_dir, y_dir, transform=None):\n",
    "        self.x_dir = x_dir\n",
    "        self.y = pd.read_csv(f'../data/{y_dir}.csv')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(os.listdir(f'../data/{self.x_dir}'))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        x = np.load(f'../data/{self.x_dir}/{idx}.npz')['data']\n",
    "        y = self.y[self.y['ID'] == idx]['TARGET'].values\n",
    "\n",
    "        # Convert to PyTorch tensors\n",
    "        x = torch.from_numpy(x).type(torch.float32)  # Assuming x is a numpy array\n",
    "        y = torch.tensor(y, dtype=torch.float32)     # Adjust dtype as per your data\n",
    "\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then i need a training loop\n",
    "def train_loop(model, loss_fn, optimizer, train_loader, device):\n",
    "    size = len(train_loader.dataset)\n",
    "    for batch, (X, y) in enumerate(train_loader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's validate the model with evaluation metrics : Mean Squared Logarithmic Error\n",
    "def test_loop(model, loss_fn, test_loader, device):\n",
    "    size = len(test_loader.dataset)\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "    test_loss /= size\n",
    "    print(f\"Test Error: \\n Avg loss: {test_loss:>8f} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define loss, optimizer, device and training/testing data\n",
    "# parameters\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "learning_rate = 1e-3\n",
    "min_learning_rate = 1e-5\n",
    "\n",
    "# Loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Optimizer\n",
    "def opt(model, learning_rate, min_learning_rate, epochs):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=min_learning_rate)\n",
    "    return optimizer, scheduler\n",
    "\n",
    "# Device\n",
    "device = torch.device('mps')\n",
    "\n",
    "# Training data\n",
    "split = 0.8\n",
    "dataset = Dataset('x_train', 'y_train')\n",
    "\n",
    "# Split data\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [int(len(dataset) * split), len(dataset) - int(len(dataset) * split)])\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a models\n",
    "# I will begin with the CNN + LSTM model. With x[data] i have 4 time steps with features of 128x128.\n",
    "# I need to use the same CNN to compute features from thoses 128x128 points.\n",
    "# Then i will use a LSTM to learn the time dependency.\n",
    "# I will then use a linear layer to predict the scalar value.\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        f1, f2, f3, f4 = 16, 16, 8, 4\n",
    "        self.conv1 = nn.Conv2d(1, f1, 3)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(f1)\n",
    "        self.conv2 = nn.Conv2d(f1, f2, 3)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(f2)\n",
    "        self.conv3 = nn.Conv2d(f2, f3, 3)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(f3)\n",
    "        self.conv4 = nn.Conv2d(f3, f4, 3)\n",
    "        self.batchnorm4 = nn.BatchNorm2d(f4)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(4, -1, 1, 128, 128)\n",
    "        x = [self.pool(self.relu(self.conv1(x[i]))) for i in range(4)]\n",
    "        x = [self.batchnorm1(x[i]) for i in range(4)]\n",
    "        x = [self.pool(self.relu(self.conv2(x[i]))) for i in range(4)]\n",
    "        x = [self.batchnorm2(x[i]) for i in range(4)]\n",
    "        x = [self.pool(self.relu(self.conv3(x[i]))) for i in range(4)]\n",
    "        x = [self.batchnorm3(x[i]) for i in range(4)]\n",
    "        x = [self.pool(self.relu(self.conv4(x[i]))) for i in range(4)]\n",
    "        x = [self.batchnorm4(x[i]) for i in range(4)]\n",
    "        x = torch.stack(x)\n",
    "        x = x.view(-1, 4, 144)\n",
    "        return x\n",
    "    \n",
    "class GRU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GRU, self).__init__()\n",
    "        self.gru = nn.GRU(144, 64, 1, batch_first=True)\n",
    "        self.linear1 = nn.Linear(64, 32)\n",
    "        self.linear2 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.cnn = CNN()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x, _ = self.gru(x)\n",
    "        x = x[:, -1, :]\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.relu(self.linear2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create metric for test purpose\n",
    "class RMSLELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, pred, actual):\n",
    "        return torch.sqrt(self.mse(torch.log(pred + 1), torch.log(actual + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU(\n",
      "  (gru): GRU(144, 64, batch_first=True)\n",
      "  (linear1): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (linear2): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (cnn): CNN(\n",
      "    (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (batchnorm1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (batchnorm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (batchnorm3): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv4): Conv2d(8, 4, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (batchnorm4): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (relu): ReLU()\n",
      "  )\n",
      ") AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0.01\n",
      ") <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x127005040>\n",
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (MPSFloatType) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/pierrejoly/Desktop/Informatique.nosync/Python/challenge-data-ens-2023/PlumeLabs_precipitation/model/analyse.ipynb Cellule 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pierrejoly/Desktop/Informatique.nosync/Python/challenge-data-ens-2023/PlumeLabs_precipitation/model/analyse.ipynb#X14sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pierrejoly/Desktop/Informatique.nosync/Python/challenge-data-ens-2023/PlumeLabs_precipitation/model/analyse.ipynb#X14sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mt\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m-------------------------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/pierrejoly/Desktop/Informatique.nosync/Python/challenge-data-ens-2023/PlumeLabs_precipitation/model/analyse.ipynb#X14sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     train_loop(model, loss_fn, optimizer, train_loader, device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pierrejoly/Desktop/Informatique.nosync/Python/challenge-data-ens-2023/PlumeLabs_precipitation/model/analyse.ipynb#X14sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     test_loop(model, loss_fn, test_loader, device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pierrejoly/Desktop/Informatique.nosync/Python/challenge-data-ens-2023/PlumeLabs_precipitation/model/analyse.ipynb#X14sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     scheduler\u001b[39m.\u001b[39mstep()\n",
      "\u001b[1;32m/Users/pierrejoly/Desktop/Informatique.nosync/Python/challenge-data-ens-2023/PlumeLabs_precipitation/model/analyse.ipynb Cellule 12\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pierrejoly/Desktop/Informatique.nosync/Python/challenge-data-ens-2023/PlumeLabs_precipitation/model/analyse.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m X, y \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(device), y\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pierrejoly/Desktop/Informatique.nosync/Python/challenge-data-ens-2023/PlumeLabs_precipitation/model/analyse.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Compute prediction error\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pierrejoly/Desktop/Informatique.nosync/Python/challenge-data-ens-2023/PlumeLabs_precipitation/model/analyse.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m pred \u001b[39m=\u001b[39m model(X)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pierrejoly/Desktop/Informatique.nosync/Python/challenge-data-ens-2023/PlumeLabs_precipitation/model/analyse.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(pred, y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pierrejoly/Desktop/Informatique.nosync/Python/challenge-data-ens-2023/PlumeLabs_precipitation/model/analyse.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Backpropagation\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/pierrejoly/Desktop/Informatique.nosync/Python/challenge-data-ens-2023/PlumeLabs_precipitation/model/analyse.ipynb Cellule 12\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pierrejoly/Desktop/Informatique.nosync/Python/challenge-data-ens-2023/PlumeLabs_precipitation/model/analyse.ipynb#X14sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/pierrejoly/Desktop/Informatique.nosync/Python/challenge-data-ens-2023/PlumeLabs_precipitation/model/analyse.ipynb#X14sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcnn(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pierrejoly/Desktop/Informatique.nosync/Python/challenge-data-ens-2023/PlumeLabs_precipitation/model/analyse.ipynb#X14sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     x, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgru(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pierrejoly/Desktop/Informatique.nosync/Python/challenge-data-ens-2023/PlumeLabs_precipitation/model/analyse.ipynb#X14sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     x \u001b[39m=\u001b[39m x[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/pierrejoly/Desktop/Informatique.nosync/Python/challenge-data-ens-2023/PlumeLabs_precipitation/model/analyse.ipynb Cellule 12\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pierrejoly/Desktop/Informatique.nosync/Python/challenge-data-ens-2023/PlumeLabs_precipitation/model/analyse.ipynb#X14sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pierrejoly/Desktop/Informatique.nosync/Python/challenge-data-ens-2023/PlumeLabs_precipitation/model/analyse.ipynb#X14sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(\u001b[39m4\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m128\u001b[39m, \u001b[39m128\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/pierrejoly/Desktop/Informatique.nosync/Python/challenge-data-ens-2023/PlumeLabs_precipitation/model/analyse.ipynb#X14sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     x \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x[i]))) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m4\u001b[39m)]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pierrejoly/Desktop/Informatique.nosync/Python/challenge-data-ens-2023/PlumeLabs_precipitation/model/analyse.ipynb#X14sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     x \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatchnorm1(x[i]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m4\u001b[39m)]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pierrejoly/Desktop/Informatique.nosync/Python/challenge-data-ens-2023/PlumeLabs_precipitation/model/analyse.ipynb#X14sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     x \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x[i]))) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m4\u001b[39m)]\n",
      "\u001b[1;32m/Users/pierrejoly/Desktop/Informatique.nosync/Python/challenge-data-ens-2023/PlumeLabs_precipitation/model/analyse.ipynb Cellule 12\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pierrejoly/Desktop/Informatique.nosync/Python/challenge-data-ens-2023/PlumeLabs_precipitation/model/analyse.ipynb#X14sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pierrejoly/Desktop/Informatique.nosync/Python/challenge-data-ens-2023/PlumeLabs_precipitation/model/analyse.ipynb#X14sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(\u001b[39m4\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m128\u001b[39m, \u001b[39m128\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/pierrejoly/Desktop/Informatique.nosync/Python/challenge-data-ens-2023/PlumeLabs_precipitation/model/analyse.ipynb#X14sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     x \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x[i]))) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m4\u001b[39m)]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pierrejoly/Desktop/Informatique.nosync/Python/challenge-data-ens-2023/PlumeLabs_precipitation/model/analyse.ipynb#X14sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     x \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatchnorm1(x[i]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m4\u001b[39m)]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pierrejoly/Desktop/Informatique.nosync/Python/challenge-data-ens-2023/PlumeLabs_precipitation/model/analyse.ipynb#X14sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     x \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x[i]))) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m4\u001b[39m)]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (MPSFloatType) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "# Let's train the model\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "learning_rate = 1e-3\n",
    "min_learning_rate = 1e-5\n",
    "loss_fn = RMSLELoss()\n",
    "model = GRU()\n",
    "\n",
    "optimizer, scheduler = opt(model, learning_rate, min_learning_rate, epochs)\n",
    "\n",
    "print(model, optimizer, scheduler)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(model, loss_fn, optimizer, train_loader, device)\n",
    "    test_loop(model, loss_fn, test_loader, device)\n",
    "    scheduler.step()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
